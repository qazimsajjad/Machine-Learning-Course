# Machine Learning (ML) Course

This repository contains comprehensive resources, code implementations, and documentation for various digital image processing techniques and algorithms. It serves as a valuable resource for students, researchers, and professionals interested in the field of image processing.

## Outlines

## Regression:
- **Linear Regression**: modeling  relationship between a dependent variable and one independent variable by fitting a linear equation to the observed data.
- **Cost Function**:  evaluating the performance of a ML model by quantifying the difference between the predicted and actual values, guiding the optimization process.
- **Optimizations**: Techniques used to adjust the parameters of model to minimize the cost function and improve model performance, including gradient descent and other optimization algorithms.
- **Mutliple Linear Regression**: An extension of linear regression that models the relationship between a dependent variable and multiple independent variables by fitting a linear equation to the observed data.
## Classification:
- **Logistic Regression**: A classification algorithm that models the probability of a binary outcome based on one or more predictor variables using a logistic function.
- **Support Vector Classifier**: modeling the relationship between input features and continuous target values by finding the optimal hyperplane that minimizes prediction errors.
- **Feature Extraction**: Methods for detecting and extracting features from images, such as LBP, SIFT, ORB, HOG and others.
- **Feature Based Learning**: Methods for training various ML algorithm to learn patterns through features.
## Artificial Neural Networks (ANN):
- Forward Pass: The process of calculating the output of a neural network by passing input data through each layer of the network.
- Backward Pass (Back Propagation): The method of adjusting the weights of a neural network by propagating the error gradient backward through the network using the chain rule.
- Shallow Networks: Neural networks with few layers, suitable for simpler problems but prone to underfitting.
- Deep Neural Networks: Neural networks with many layers, capable of modeling complex patterns but at risk of overfitting.
## Implementation:
Each lecture includes the following implementations:
- **Manual Implementation**: Concepts are implemented using numpy without relying on built-in machine learning libraries, offering a clear understanding of the underlying mechanics.
- **scikit-learn Implementation**: Demonstrates basic machine learning models using scikit-learn's built-in functionalities for ease of use and efficiency.
- **Keras Implementation**: Utilizes the high-level Keras API, which provides user-friendly implementations of specialized machine learning and deep learning models with both sequential and functional approaches.
- **PyTorch Implementation**: Employs the PyTorch framework, known for its flexibility and research-oriented design, to implement neural networks with full control over their architecture and training process.
  
## Getting Started

1. **Clone the Repository**:
    ```sh
    git clone https://github.com/qazimsajjad/Machine-Learning-Course.git
    ```
2. **Navigate to the Directory**:
    ```sh
    cd Machine-Learning-Course
    ```
3. **Install Dependencies**:
    ```sh
    python => 3.9
    numpy
    matplotlib
    pillow
    opencv
    sk-learn
    torch
    keras
    tensorflow
    
    ```

## Usage

Open the Jupyter Notebooks provided in the repository to explore different **Machine Learning** techniques. Each notebook contains detailed explanations, code implementations, and example images to help you understand the concepts.

## Contributor:

**Kaleem Ullah**
Research Assitant **Digital Image Processing (DIP) Lab** Department of Computer Scinece Islamia College University, Peshawar, Pakistan.
Remote Research Assistant **Visual Analytics Lab (VIS2KNOW)** Department of Applied AI Sungkyunkwan University, Seoul, South Korea.
